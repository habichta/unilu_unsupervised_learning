{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increase width of Notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM on Old Faithful Geyser Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Path to CSV file\n",
    "data_path = 'data/faithful.csv'\n",
    "\n",
    "#Image path for fun\n",
    "img = mpimg.imread('data/old_faithful.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load CSV and remove NaN\n",
    "old_faithful_data = np.genfromtxt(data_path, delimiter=',')[1:,1:]\n",
    "print(old_faithful_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Functions to reuse plots\n",
    "def plot_old_faithful_data(old_faithful_data):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "    ax[0].scatter(old_faithful_data[:,0], old_faithful_data[:,1])\n",
    "    ax[0].set_title('Old Faithful Eruptions')\n",
    "    ax[0].set(xlabel='Eruption time (s)', ylabel='Wait time (s)')\n",
    "    ax[1].imshow(img)\n",
    "    ax[1].set_xticks([])\n",
    "    ax[1].set_yticks([])\n",
    "    \n",
    "def plot_old_faithful_data_gmm(old_faithful_data, gmm):\n",
    "    x = np.linspace(0., 6.)\n",
    "    y = np.linspace(0., 130.)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "    Z = -gmm.score_samples(XX)\n",
    "    Z = Z.reshape(X.shape)\n",
    "\n",
    "    CS = plt.contour(X, Y, Z, norm=LogNorm(vmin=1.0, vmax=100.0),\n",
    "                     levels=np.logspace(0, 2, 15))\n",
    "    CB = plt.colorbar(CS, shrink=0.9, extend='both')\n",
    "    plt.scatter(old_faithful_data[:, 0], old_faithful_data[:, 1], .8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of Old Faithful data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_old_faithful_data(old_faithful_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar arguments as in k-Means (a bit more)\n",
    "n_components=2\n",
    "gmm = GaussianMixture(n_components=n_components).fit(old_faithful_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilities for each data point (to which cluster they belong, soft assignment)\n",
    "gmm.predict_proba(old_faithful_data)\n",
    "\n",
    "#hard_assignment like k-Means\n",
    "gmm.predict(old_faithful_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_old_faithful_data_gmm(old_faithful_data, gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do I find the right number of clusters?\n",
    "- Similar to k-Means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Information Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic=[]\n",
    "for n_components in range(1,10):\n",
    "        gmm = GaussianMixture(n_components=n_components).fit(old_faithful_data)\n",
    "        bic.append(gmm.bic(old_faithful_data))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,len(bic)+1),bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Akaike Information Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic=[]\n",
    "for n_components in range(1,10):\n",
    "        gmm = GaussianMixture(n_components=n_components).fit(old_faithful_data)\n",
    "        aic.append(gmm.aic(old_faithful_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,len(aic)+1),aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a fake Old Faithful?\n",
    "We can sample from the fitted GMM to generate synthetic data that looks \"real\". This is like creating fake faces with GANs (just much simpler data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fake_old_faithful(weights, means, covariances, samples=300):\n",
    "    data_points = []\n",
    "    for _ in range(samples):\n",
    "        selected_component = np.random.choice([0,1], size=1, p=weights)\n",
    "        comp_mean = means[selected_component].squeeze()\n",
    "        comp_cov = covariances[selected_component].squeeze()\n",
    "        data_point = np.random.multivariate_normal(comp_mean,comp_cov)\n",
    "        data_points.append(data_point)\n",
    "    \n",
    "    return np.array(data_points)\n",
    "        \n",
    "\n",
    "gmm = GaussianMixture(n_components=2).fit(old_faithful_data)\n",
    "component_weights = gmm.weights_\n",
    "component_means = gmm.means_\n",
    "component_covariances = gmm.covariances_\n",
    "\n",
    "fake_old_faithful_data = create_fake_old_faithful(component_weights, component_means, component_covariances)\n",
    "\n",
    "plot_old_faithful_data(fake_old_faithful_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One more important thing...\n",
    "\n",
    "- We used the raw data. Often it is useful to scale the data or perform additional preprocessing on the raw data before using a Cluster algorithm.\n",
    "\n",
    "- Look at `StandardScaler` or `MinMaxScaler` as a start for your projects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scikit-learn GMM](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
